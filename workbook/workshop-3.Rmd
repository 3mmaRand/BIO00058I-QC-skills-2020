---
title:  "Topic 3: Generalised Linear Models for Binomially distributed data."
author: "Emma Rand"
output:
  html_document:
    toc: true
    depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: false
    theme: yeti
  word_document: default
---
![](../pics/58I.png)
```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE,
                      messgsize = FALSE,
                      warning = FALSE,
                      include = FALSE)
```

```{r pkgs}
library(tidyverse)
library(multcomp)
```

# Introduction

## Aims
There are two aims for this topic. First to explain how the t-test, ANOVA and regression are actually all the same test and introduce the terminology of statistical modelling and, secondly, to teach you how to use and interpret the `lm()` function in R. 

## Aims
The aim for this topic is to teach you how to use and interpret the `glm()` function in R for response data which are Poisson distributed (counts). 

## Objectives 
By doing the independent study before each Blackboard workshop and working with others to solve workshop problems the successful student will be able to:

* Explain the link between the general linear models and the generalised linear model
* Recognise a Poisson distributed response variable
* Appropriately apply generalised linear models to binomially distributed data using `glm()`
* Interpret and report the results 

## Independent Study
The independent study required was to read the Preface and chapters 5 and 6 of [singlm:](https://3mmarand.github.io/singlm/) ***S**imple **In**troduction to **GLM** for analysing Poisson and Binomial responses in R*.


# Instructions

Designate roles: 

1. the code host  
2. the report host  
3. chat monitor
4. the researchers

The code host opens RStudio and shares their screen. They type the code and comments that you collaboratively write. The report host creates a googledoc which they share with all the group members. You collaboratively write the googledoc. I suggest the start is used for ideas and comments before you add a report you collaboratively write. At the start of a problem the code host shares their screen showing RStudio and towards the end, the report host will share their screen.
The chat monitor makes sure everyone is aware of breaking news and ideas in the chat that they might miss if focussed on the googledoc or RStudio. The researchers keep the group on track making sure the items in the list below are addressed and looking up things in 17C / 08C and [singlm:](https://3mmarand.github.io/singlm/)

<font size = "4">
`r emo::ji("heart")` Be kind, be understanding, be flexible  
`r emo::ji("document")` Use collaborative notes - document your ideas and process.  
`r emo::ji("flower")` Contribute actively to the coding and reporting - your code and report hosts should not feel they have all the responsibility.  
`r emo::ji("heart")`Allow people to contribute to the process silently by writing in the googledoc or using the chat  
</font>

For each data scenario:

* use a new RStudio Project containing folders: `data-raw`, `scripts` and `figures`
* check you understand the structure of the data
* identify the response and explanatory variables
* make a quick plot of the data and summarise it
* build a model with `glm()` and examine it using `summary()`
* what are the model coefficients and how do these relate to the response?  
* what is the null deviance of the response? And the residual deviance of model? 
* determine the reduction in deviance and whether it is significant 
* use `predict()` to make predictions for a set sensible values for the explanatory variable(s)   
* write a report on the results. This will be no more than a few sentences reporting the results and an accompanying figure which you also write to file. 
* post your report to the Padlet
* go through your code adding comments, removing code that no longer reflects steps in your analysis and reporting, and reordering where necessary  
* examine some of the other reports posted on the Padlet. What did you do well? What could you have done better? Add these as comments to your own Padlet post
* make sure the RStudio Project and the googledoc is shared with everyone in your group

# Data scenarios

## 1. Wolf beach

Suzuki et al. (2006) measured sand grain size (mm) on 28 beaches in Japan and observed the presence or absence of the burrowing wolf spider *Lycosa ishikariana* on each beach. The data are in [grainsize.txt](../data-raw/grainsize.txt). Can you predict the presence of beach from the sand grain size? 


```{r }
# The effect of sand grain size on the presence of wolf spiders

# library(tidyverse)
# read in the data file
beach <- read_table2("../data-raw/grainsize.txt")

# check you understand the structure of the data
str(beach)
# there is one continuous numeric and one variable which takes the value zero or 1

# identify the response and explanatory variables
# the response is 'spiders', the presence or absence of wolf spiders on a beach; gsize, sand grain size, is the explanatory variable

# make a quick plot of the data and summarise it
ggplot(data = beach, aes(x = gsize, y = spiders)) +
  geom_point()
# perhaps spiders are less likely to be present when the grain size is small

# build a model with `glm()` and examine it using `summary()`
mod <- glm(data = beach, spiders ~ gsize, family = binomial)

# what are the model coefficients?
mod # coefficient are log odds, need to be exponentiated for odds
exp(mod$coefficients)
# exp(b0) is the odds of a spider being present is 0.19 at a grain size of 0. Odds are P(present) / P(absent). As this is less than 1, the probability of being present must be smaller than the probability of being absent at a grainsize of 0. 
# exp(b1) is the factor by which this odds changes with each unit of grainsize. b1 is 167.6. This is very large because the grain sizes are in mm and 1 mm is a huge change in grainsize
# the equation of the line is ln(spiders)  = -1.647625 + 5.121553 Ã— gsize or
# spiders = 0.1925066 * 167.5954097^gsize

# what is the null deviance of the response? And the residual deviance of model? 
summary(mod)
# the Null deviance is 35.165  and the Residual deviance is 30.632

# determine the reduction in deviance and whether it is significant 
35.165 - 30.632
# the deviance has reduced by 4.533
anova(mod, test = "Chisq")
# this is a significant reduction p = 0.03324


# use `predict()` to make predictions for a set sensible values for the explanatory variable(s)   
# here I do it for gsizes of 0, 0.5 and 1 mm
# create a data frame of the x values from which you want to predict
predict_for <- data.frame(gsize = c(0, 0.5, 1))
# add predictions to that data.frame
predict_for$pred <- predict(mod, newdata = predict_for, type = "response")
predict_for
#   gsize      pred
# 1   0.0 0.1614302
# 2   0.5 0.7136446
# 3   1.0 0.9699368
# a bit on understanding odds
# An odds is P(present) / P(absent)
# At a grain size of 0, P(present) is 0.1614302, therefore p(absent) is 1-0.1614302
# 0.1614302/(1-0.1614302) = 0.1925066. Look! that's exp(b0)!
# How does this change from grain size of 0 to grain size of 1?
# At a grain size of 1, P(present) is 0.9699368, therefore p(absent) is 1-0.9699368
# the factor by which the odds change is the odds of present at grainsize 1 /
# odds of present at grainsize 0
# (0.9699368/(1-0.9699368)) / (0.1614302/(1-0.1614302))
# = 167.5956 Look, that's exp(b1)
# Odds are not intuitive for most people. I almost always use the predict function to calculate probabilities to help me understand the effects in my model.
# You can still make quick judgement on the basis of the coefficients
# negative b0 means probability of absence (or died/0/no) is higher than probability of presence (or survived/1/yes); positive b0 means probability of presence is higher than probability of absence
# negative b0 means odds of get lower, presence gets less likely
# positive b0 means odds of get higher, presence gets less likely

# write a report on the results. This will be no more than a few sentences reporting the results and an accompanying figure which you also write to file. 
p <- ggplot(data = beach, aes(x = gsize, y = spiders)) +
  geom_point() +
geom_smooth(method = "glm",
              method.args = list(family = "binomial"),
              se = FALSE,
            colour = "black") +
  scale_x_continuous(expand = c(0, 0),
                     limits = c(0, 1.2),
                     name = "Grain size (mm)") +
    scale_y_continuous(expand = c(0, 0.03),
                      breaks = seq(0, 1, 0.1),
                     limits = c(0, 1.05),
                     name = "Presence of wolf spiders") +
  theme_classic()

ggsave("../figures/spiders.tif", 
       plot = p, 
       device = "tiff",
       width = 3.2, 
       height = 3.2,
       units = "in",
       dpi = 300)
#
```

## 2. Effect of alcohol consumption on the incidence of Oesophageal cancer

Thirty men aged 55 years and over were surveyed for their alcohol consumption then followed up 10 years later for the occurrence of Oesophageal cancer. The data are in [oesoph.txt](../data-raw/oesoph.txt) and comprise two variables:

* status : a variable which indicates whether the individual had developed oesophgsizeal cancer (1) or not (0)  
* alcohol :  the amount of alcohol consumed per week in grams  


```{r}
# The effect alcohol consumption on the occurrence of Oesophageal cancer
# library(tidyverse)
# read in the data file
cancer <- read_table2("../data-raw/oesoph.txt")

# check you understand the structure of the data
str(cancer)
# there is one continuous numeric and one variable which takes the value zero or 1

# identify the response and explanatory variables
# the response is 'status', the presence or absence Oesophageal cancer; alcohol, the amount of alcohol consumed per week in grams, is the explanatory variable

# make a quick plot of the data and summarise it
ggplot(data = cancer, aes(x = alcohol, y = status)) +
  geom_point()
# perhaps cancer is more common for those that consume more alcohol 

# build a model with `glm()` and examine it using `summary()`
mod <- glm(data = cancer, status ~ alcohol, family = binomial)

# what are the model coefficients?
mod # coefficient are log odds, need to be exponentiated for odds
exp(mod$coefficients)
# exp(b0) is the odds of cancer being present is 0.006841727 at an alcohol consumption of 0. Odds are P(present) / P(absent). As this is less than 1, the probability of cancer being present must be smaller than the probability of cancer being absent at an alcohol of 0. 
# exp(b1) is the factor by which this odds changes with each gram of alcohol b1 is 1.088605775. 
# the equation of the line is ln(status)  = -4.9847 + 0.0849 Ã— alcohol or
# status = 0.006841727 * 1.088605775 ^alcohol

# what is the null deviance of the response? And the residual deviance of model? 
summary(mod)
# the Null deviance is 27.034    and the Residual deviance is 22.863  

# determine the reduction in deviance and whether it is significant 
27.034 - 22.863  
# the deviance has reduced by 4.171
anova(mod, test = "Chisq")
# this is a significant reduction p = 0.04112 


# use `predict()` to make predictions for a set sensible values for the explanatory variable(s)   
# here I do it for alcohol of 0 to 60 in steps of 10
# create a data frame of the x values from which you want to predict
predict_for <- data.frame(alcohol = seq(0, 60, 10))
# add predictions to that data.frame
predict_for$pred <- predict(mod, newdata = predict_for, type = "response")
predict_for
#   alcohol        pred
# 1       0 0.006795236
# 2      10 0.015739186
# 3      20 0.036028214
# 4      30 0.080336635
# 5      40 0.169552201
# 6      50 0.323042084
# 7      60 0.527260746
# a bit on understanding odds
# to demonstrate the link between the model estimates and the predicted probabilities like I did in the first example, I will need the predicted probabilities at alcohol = 1 (because a b1, by definition, relates to one unit change)
predict(mod, newdata = data.frame(alcohol = 1), type = "response")
# which gives 0.007392882 
# An odds is P(present) / P(absent)
# At alcohol of 0, P(present) is 0.006841727, therefore p(absent) is 1-0.006795236
# 0.006795236/(1-0.006795236) = 0.006841727. Look! that's exp(b0)!
# How does this change from alcohol of 0 to alcohol of 1?
# At alcohol of 1, P(present) is 0.006841727, therefore p(absent) is 1-0.006841727
# the factor by which the odds change is the odds of present at alcohol of 1 /
# odds of present at alcohol of 0
# (0.007392882 /(1-0.007392882 )) / (0.006841727/(1-0.006841727))
# = 1.081158 Look, that's exp(b1)
# Odds are not intuitive for most people. I almost always use the predict function to calculate probabilities to help me understand the effects in my model.
# You can still make quick judgement on the basis of the coefficients
# negative b0 means probability of absence (or died/0/no) is higher than probability of presence (or survived/1/yes); positive b0 means probability of presence is higher than probability of absence
# negative b0 means odds of get lower, presence gets less likely
# positive b0 means odds of get higher, presence gets less likely

# write a report on the results. This will be no more than a few sentences reporting the results and an accompanying figure which you also write to file. 
p <- ggplot(data = cancer, aes(x = alcohol, y = status)) +
  geom_point() +
geom_smooth(method = "glm",
              method.args = list(family = "binomial"),
              se = FALSE,
            colour = "black") +
  scale_x_continuous(expand = c(0, 0),
                     limits = c(0, 70),
                     name = "Alcohol consumed (g/week)") +
    scale_y_continuous(expand = c(0, 0.03),
                      breaks = seq(0, 1, 0.1),
                     limits = c(0, 1.05),
                     name = "Presence of Oesophageal cancer") +
  theme_classic()

ggsave("../figures/oesophageal_cancer.tif", 
       plot = p, 
       device = "tiff",
       width = 3.2, 
       height = 3.2,
       units = "in",
       dpi = 300)

```



# The Rmd file

[Rmd file](workshop-3.Rmd)


![](../pics/58Iend.png)



